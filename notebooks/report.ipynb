{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T21:41:09.053414Z",
     "start_time": "2025-03-05T21:41:08.554699Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Артефакты моделей\n",
    "\n",
    "Артефакты моделей были загружены в соответствующий репозиторий на [HuggingFace]()\n",
    "\n",
    "За основу для экспериментов по DPO-алайменту была взята инструктированная модель [SmolLM2-135M-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct). В качестве набора данных использовался был взят [ultrafeedback_binarized](https://huggingface.co/datasets/trl-lib/ultrafeedback_binarized).\n",
    "\n",
    "\n",
    "Параметры обучения\n",
    "\n",
    "шаг обучения 5e-5\n",
    "beta 0.1\n",
    "bf16 = True\n",
    "logging_steps = 1\n",
    "\n",
    "max_promt_length = 1024\n",
    "max_length = 1536\n",
    "\n",
    "\n",
    "### __Параметры для Reverse KL__\n",
    "\n",
    "Шаг обучения $5e-5$, коэффициент при слагаемом дивергенции $\\beta \\in [0.05, 0.1, 1.0, 5.0]$, размер батча $4$, шаг накопления градиента $4$, количество итераций $200$, максимальная длина промтов $1024$\n",
    "\n",
    "### __Параметры для Forward KL__\n",
    "\n",
    "Шаг обучения $5e-5$, коэффициент при слагаемом дивергенции $\\beta = 0.1$, размер батча $4$, шаг накопления градиента $4$, количество итераций $200$, максимальная длина промтов $1024$\n",
    "\n",
    "### __Параметры для $\\alpha$-divergence__\n",
    "\n",
    "Шаг обучения $5e-5$, коэффициент при слагаемом дивергенции $\\beta = 0.1$, показатель степени $\\alpha$-дивергенции $\\alpha=0.5$, размер батча $4$, шаг накопления градиента $4$, количество итераций $200$, максимальная длина промтов $1024$\n",
    "\n",
    "### __Параметры для JS-divergence__\n",
    "\n",
    "Шаг обучения $5e-5$, коэффициент при слагаемом дивергенции $\\beta = 0.1$, размер батча $4$, шаг накопления градиента $4$, количество итераций $200$, максимальная длина промтов $1024$\n",
    "\n",
    "### __Параметры генерации ответов__\n",
    "\n",
    "\n",
    "### __Как рассчитывалась KL-дивергенция__\n",
    "\n",
    "Фиксируем 100 тестовых промтов. Двумя взятыми моделями генерируем ответы для каждого промта. На основе выходных логитов модели рассчитываем KL-дивергенцию для каждой пары ответов. В конце усредняем."
   ],
   "id": "bc461ba7e951f537"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3cc831c425a89abb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
